# -*- coding: utf-8 -*-
"""train.py

Automatically generated by Colaboratory.
For use with :  https://colab.research.google.com/drive/1cBUf2Igfx9eLVbQbCoG2OulwPcdi3ARD

"""

# Imports
import numpy as np
import os

from tflite_model_maker.config import ExportFormat, QuantizationConfig
from tflite_model_maker import model_spec
from tflite_model_maker import object_detector

from tflite_support import metadata

import tensorflow as tf
assert tf.__version__.startswith('2')

# # GPU Fix from https://stackoverflow.com/a/69545925
# gpus = tf.config.list_physical_devices('GPU')
# if gpus:
#     try:
#     # Currently, memory growth needs to be the same across GPUs
#         for gpu in gpus:
#             tf.config.experimental.set_memory_growth(gpu, True)
#         logical_gpus = tf.config.list_logical_devices('GPU')
#         print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
#     except RuntimeError as e:
#     # Memory growth must be set before GPUs have been initialized
#         print(e)


tf.get_logger().setLevel('ERROR')
from absl import logging
logging.set_verbosity(logging.ERROR)

# Confirm TF Version
print("\nTensorflow Version:")
print(tf.__version__)
print()

# Load Dataset
train_data = object_detector.DataLoader.from_pascal_voc(
    'shapes/train/images', # training images
    'shapes/train/annotations', # annotations
    ['box', 'circle', 'path', 'tree', 'x'] # class names
)

val_data = object_detector.DataLoader.from_pascal_voc(
    'shapes/validate/images', # validation images
    'shapes/validate/annotations', # validation annotations
    ['box', 'circle', 'path', 'tree', 'x'] # class names
)

# Load model spec
spec = object_detector.EfficientDetSpec(
  model_name='efficientdet-lite2',
  uri='https://tfhub.dev/tensorflow/efficientdet/lite2/feature-vector/1',
  model_dir='/content/checkpoints',
  hparams={'max_instances_per_image': 8000})

# Train the model
model = object_detector.create(train_data, model_spec=spec, batch_size=10, train_whole_model=True, epochs=20, validation_data=val_data)

# Evaluate the model
eval_result = model.evaluate(val_data)

# Print COCO metrics
print("COCO metrics:")
for label, metric_value in eval_result.items():
    print(f"{label}: {metric_value}")

# Add a line break after all the items have been printed
print()

# Export the model
model.export(export_dir='.', tflite_filename='android.tflite')

# Evaluate the tflite model
tflite_eval_result = model.evaluate_tflite('android.tflite', val_data)

# Print COCO metrics for tflite
print("COCO metrics tflite")
for label, metric_value in tflite_eval_result.items():
    print(f"{label}: {metric_value}")